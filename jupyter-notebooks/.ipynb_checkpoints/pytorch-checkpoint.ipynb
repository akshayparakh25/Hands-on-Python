{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to summarize the properties of a tensor\n",
    "def describe(x):\n",
    "    print(\"Type :: {}\".format(x.type()))\n",
    "    print(\"Data Type :: {}\".format(x.dtype))\n",
    "    print(\"Size :: {}\".format(x.size()))\n",
    "    print(\"Shape :: {}\".format(x.shape))\n",
    "    print(\"Number of elements :: {}\".format(x.numel()))\n",
    "    # Dimension :: x.ndimension()\n",
    "    print(\"Dimension :: {}\".format(x.dim()))\n",
    "    print(\"Data :: \\n{}\".format(x))\n",
    "    print('-----'*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar (0-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalar (o-d Tensor)\n",
    "s = torch.tensor(2504)\n",
    "describe(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector (1-d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing a Tensor directly using python list\n",
    "Using Tensor object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.Tensor([25, 4])\n",
    "describe(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m.type(torch.LongTensor)\n",
    "describe(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tensor() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using torch.tensor(), can specify data types\n",
    "m = torch.tensor([25, 4], dtype=torch.int32)\n",
    "describe(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.tensor() infer the type of the data automatically, <br>\n",
    "torch.Tensor() is an alias of torch.FloatTensor() <br>\n",
    "prefer torch.tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer and Float lists to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_list = [1,2,3,4,5]\n",
    "float_list = [1.0,2.0,3.0,4.0,5.0]\n",
    "\n",
    "int_tensor = torch.tensor(int_list)\n",
    "describe(int_tensor)\n",
    "\n",
    "float_int_tensor = torch.tensor(float_list, dtype=torch.int64)\n",
    "describe(float_int_tensor)\n",
    "\n",
    "float_tensor = torch.tensor(float_list)\n",
    "describe(float_tensor)\n",
    "\n",
    "int_float_tensor = torch.FloatTensor(int_list)\n",
    "describe(int_float_tensor)\n",
    "\n",
    "new_flot_tensor = torch.tensor(int_list, dtype=torch.float64)\n",
    "describe(new_flot_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_flot_tensor.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix (2-d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing a Tensor directly \n",
    "#Creates an unitilised matrix of size 5x4\n",
    "c = torch.Tensor(5,4)\n",
    "describe(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising using numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialized with numpy array\n",
    "n = torch.tensor(np.array([25, 4], dtype=np.int32))\n",
    "describe(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10)\n",
    "tensor_a = torch.from_numpy(a)\n",
    "describe(tensor_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_to_numpy_a = tensor_a.numpy()\n",
    "back_to_numpy_a, back_to_numpy_a.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_series = pd.Series(np.arange(1,11,2))\n",
    "print(pd_series)\n",
    "tensor_fron_series = torch.from_numpy(pd_series.values)\n",
    "describe(tensor_fron_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[11,21,31],'b':[12,22,312]})\n",
    "print(df)\n",
    "tensor_fron_dataframe = torch.from_numpy(df.values)\n",
    "describe(tensor_fron_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Tensor Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empt = torch.empty(10)\n",
    "describe(empt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.zeros(2,3,4)\n",
    "describe(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.ones()\n",
    "#Constructing a tensor using the existing Tensor\n",
    "o = torch.ones_like(z)\n",
    "describe(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filled with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can also create tensor filled with same value\n",
    "#torch.fill(shape)\n",
    "z.fill_(25) #_ ===> in-place operation\n",
    "describe(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagonal Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a diagonal matrix tensor using the data\n",
    "d = torch.diag(torch.Tensor([1,2,3,4]))\n",
    "describe(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating an identity matrix\n",
    "i = torch.eye(5,5)\n",
    "describe(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialised with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a tensor insitialised with 10 uniform random values\n",
    "x = torch.rand(10)\n",
    "describe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a normal distribution tensor of shape x\n",
    "x_normal = torch.randn_like(x)\n",
    "describe(x_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randint(start, end, size(must be a tuple))\n",
    "rand_ints = torch.randint(0, 100, (5, 4))\n",
    "describe(rand_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linspace(start, end, number of elements)\n",
    "ls = torch.linspace(20, 30, 25)\n",
    "describe(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#range(start, end, skip)\n",
    "rg = torch.range(0, 100, 3)\n",
    "describe(rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing & Slicing\n",
    "Accessing elements, rows, columns, sub-tensor from a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ints.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing and Slicing\n",
    "#3rd row, 2nd and 3rd column\n",
    "rand_ints[2, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ints[2, 1:3] = torch.Tensor([19, 91])\n",
    "rand_ints.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first column\n",
    "rand_ints[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first 2 row\n",
    "rand_ints[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 3 column\n",
    "rand_ints[:,-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last row\n",
    "rand_ints[-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-contiguous indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access 2nd and 4th col\n",
    "indices = torch.LongTensor([1,3]) # Index must be integers\n",
    "describe(torch.index_select(rand_ints, dim=1, index=indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access 2nd and 4th row\n",
    "describe(torch.index_select(rand_ints, dim=0, index=indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.arange(1, 21, dtype=torch.int32)\n",
    "describe(a)\n",
    "reshaped_a = a.view(2,2,5)\n",
    "describe(reshaped_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dynamic size arrays or when size is unknown\n",
    "# -1 is inferred from other dimension\n",
    "reshaped_a = a.view(-1,1)\n",
    "describe(reshaped_a)\n",
    "reshaped_a = a.view(10,-1)\n",
    "describe(reshaped_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Functions\n",
    "#### sum(), max(), mean(), median(), min(), std(), etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 3d tensors, dim=0 represents 2D tenasors, dim=1 represents rows, dim=2 represents column\n",
    "a = a.view(2,2,5)\n",
    "a.sum(), a.sum(dim=0), a.sum(dim=1), a.sum(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenation of tensors: cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.view(4, 5)\n",
    "describe(torch.cat((a,a), dim=1))\n",
    "print(\"\\n\")\n",
    "describe(torch.cat((a,a), dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnsr = torch.linspace(0, 2*np.pi, 100)\n",
    "sin_tnsr = torch.sin(tnsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tnsr.numpy(), sin_tnsr.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset and converting to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix of size 506x13\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "boston.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_numpy converts numpy array to pytorch tensor\n",
    "boston_data = torch.from_numpy(boston.data)\n",
    "boston_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing element from columns 3 to 7 from first 2 rows of a tensor\n",
    "boston_data[:2, 3:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arithmetic operations +-*/\n",
    "a = torch.rand(2,2)\n",
    "b = torch.rand(2,2)\n",
    "\n",
    "c = a+b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ signifies for inplace operation(Here, addition)\n",
    "a.add_(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_tensor = torch.tensor([25], dtype=torch.int32)\n",
    "describe(one_value_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using item() to access te value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_value_tensor.item(), c[0][0], c[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Algebra\n",
    "x1 = torch.arange(6).view(2,3)\n",
    "x2 = torch.randint(1, 11, (3,1))\n",
    "print(\"x1\", \"\\n============\")\n",
    "describe(x1)\n",
    "print(\"============\\n\")\n",
    "print(\"x2\", \"\\n============\")\n",
    "describe(x2)\n",
    "print(\"============\\n\")\n",
    "print(\"x1 matmul x2\", \"\\n============\")\n",
    "describe(torch.matmul(x1, x2))\n",
    "print(\"============\\n\")\n",
    "print(\"x1 transpose\", \"\\n============\")\n",
    "describe(torch.transpose(x1, 0, 1))\n",
    "print(\"============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector Dot Product\n",
    "v1 = torch.tensor([1,2,3])\n",
    "v2 = torch.tensor([4,5,6])\n",
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hadamard Product (Element wise product)\n",
    "v1*v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives and tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(2,5)\n",
    "print(t.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is a tensor initialised with value 2\n",
    "#requires_grad as True, it starts to track all operations on it.\n",
    "x = torch.tensor(2, dtype=torch.float64, requires_grad=True)\n",
    "print(x)\n",
    "#y = f(x)\n",
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating derivative using backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x ::\", x)\n",
    "print(\"x data :: \", x.data)\n",
    "print(\"x  gradient :: \", x.grad)\n",
    "print(\"x gradient function :: \", x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y ::\", y)\n",
    "print(\"y data :: \", y.data)\n",
    "print(\"y  gradient :: \", y.grad)\n",
    "print(\"y gradient function :: \", y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finish all computation then can call .backward() and have all the gradients computed automatically.\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = x ** 2 <br>\n",
    "dy/dx = 2 * x <br>\n",
    "dy/dx at x=2 :: 2 * 2 :: 4 => x.grad <br>\n",
    "The gradient for this tensor will be accumulated into .grad attribute. <br>\n",
    " .grad_fn attribute that references a Function that has created the Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x ::\", x)\n",
    "print(\"x data :: \", x.data)\n",
    "print(\"x  gradient :: \", x.grad)\n",
    "print(\"x gradient function :: \", x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y ::\", y)\n",
    "print(\"y data :: \", y.data)\n",
    "print(\"y  gradient :: \", y.grad)\n",
    "print(\"y gradient function :: \", y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Rule: dz/dx = dz/dy * dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(2, dtype=torch.float64, requires_grad=True)\n",
    "y = x ** 2\n",
    "z = (y ** 3) * 3\n",
    "\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x ::\", x)\n",
    "print(\"x data :: \", x.data)\n",
    "print(\"x  gradient :: \", x.grad)\n",
    "print(\"x gradient function :: \", x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y ::\", y)\n",
    "print(\"y data :: \", y.data)\n",
    "print(\"y  gradient :: \", y.grad)\n",
    "print(\"y gradient function :: \", y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"z ::\", z)\n",
    "print(\"z data :: \", z.data)\n",
    "print(\"z  gradient :: \", z.grad)\n",
    "print(\"z gradient function :: \", z.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor(2, dtype=torch.float64)\n",
    "u.requires_grad_(True)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor(3, dtype=torch.float64, requires_grad=True)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = f(u, v)\n",
    "y = u*v + u**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dy/du = df(u, v)/du = v + 2u = 3 + 2 * 2 = 7 => u.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"u ::\", u)\n",
    "print(\"u data :: \", u.data)\n",
    "print(\"u  gradient :: \", u.grad)\n",
    "print(\"u gradient function :: \", u.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dy/dv = df(u, v)/dv = u = 2 => v.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"v ::\", v)\n",
    "print(\"v data :: \", v.data)\n",
    "print(\"v  gradient :: \", v.grad)\n",
    "print(\"v gradient function :: \", v.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y ::\", y)\n",
    "print(\"y data :: \", y.data)\n",
    "print(\"y  gradient :: \", y.grad)\n",
    "print(\"y gradient function :: \", y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sometimes some parameters need not to be updated: Use with torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.requires_grad_(True)\n",
    "print(t)\n",
    "with torch.no_grad():\n",
    "    print((t**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To stop a tensor from tracking history, you can call .detach()\n",
    "#particularly helpful when evaluating a model \n",
    "#because the model may have trainable parameters with requires_grad=True, \n",
    "#but for which we don’t need the gradients.\n",
    "print(t)\n",
    "t.detach_()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-10, 10, 10, requires_grad = True)\n",
    "w = torch.linspace(-10, 10, 10, requires_grad = True)\n",
    "\n",
    "Y = x ** 2\n",
    "Z = torch.relu(w)\n",
    "\n",
    "y = torch.sum(Y)\n",
    "z = torch.mean(Z)\n",
    "\n",
    "#torch.autograd cannot compute full Jacobian directly\n",
    "#input to backward must be scalar.\n",
    "#if it is not scalar, need to pass a vector for vector jacobian product.\n",
    "y.backward()\n",
    "z.backward()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax0 = plt.subplot(121)\n",
    "ax0.plot(x.detach().numpy(), Y.detach().numpy(), label = 'function')\n",
    "ax0.plot(x.detach().numpy(), x.grad.detach().numpy(), label = 'derivative')\n",
    "ax0.set_xlabel('x')\n",
    "ax0.set_title('Square Function')\n",
    "\n",
    "ax1 = plt.subplot(122)\n",
    "ax1.plot(w.detach().numpy(), Z.detach().numpy(), label = 'function')\n",
    "ax1.plot(w.detach().numpy(), w.grad.detach().numpy(), label = 'derivative')\n",
    "ax1.set_xlabel('w')\n",
    "ax1.set_title('Relu Function')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check this [link](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html) for detailed explaination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables are wrapper around the tensor ith gradient and reference to a function that created it.\n",
    "from torch.autograd import Variable\n",
    "x = Variable(torch.ones(2,2), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tensors can be moved to any device.\n",
    "#Following code checks if GPU is available, maked cuda (GPU) default device.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "x3 = torch.rand(2,5).to(device)\n",
    "if device == \"cuda\":\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(x3.type())\n",
    "else:\n",
    "    print(device)\n",
    "    print(x3.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class and loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "#Forces to give same random number every time it gets compiled\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Custom dataset should inherit Dataset and override,\n",
    "1. __init__()\n",
    "2. __len__()\n",
    "3. __getitem__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to load sample dummy dataset\n",
    "class toyDataset(Dataset):\n",
    "    #Constructor with default values\n",
    "    def __init__(self, length=10, transform=None):\n",
    "        self.len = length\n",
    "        #x :: input features\n",
    "        self.x = 2 * torch.randint(0, 101,(length, 2), dtype=torch.float64)\n",
    "        #y :: target labels\n",
    "        self.y = torch.ones(length, 1)\n",
    "        #Whether data need to transformed (like, normalization, etc)\n",
    "        self.transform = transform\n",
    "        \n",
    "    #Method overriding to return the total number of instances \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    #Method overriding to return data samples\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating instance of toyDataset and accessing example instances\n",
    "data = toyDataset()\n",
    "for i in range(5):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "Most of time, we need to do some type of tranformation in the dataset, like normalising the data, setting the image size, etc. Thus, there is need to write some pre-processing code. <br>\n",
    "It is ideal to implement them as class rather than functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transform_my_data(object):\n",
    "    def __init__(self, tranformation_params):\n",
    "        \"\"\"\n",
    "            Constructor\n",
    "        \"\"\"\n",
    "        self.tranformation_params = tranformation_params\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "            Executor:\n",
    "            Necessary tranformation\n",
    "            to each instance of data.\n",
    "            \n",
    "        \"\"\"\n",
    "        x, y = sample\n",
    "        x *= self.tranformation_params\n",
    "        \n",
    "        return x, y       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalise_my_data(object):\n",
    "    def __init__(self, total_instances):\n",
    "        \"\"\"\n",
    "            Constructor\n",
    "        \"\"\"\n",
    "        self.total_instances = total_instances\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "            Executor:\n",
    "            Necessary tranformation\n",
    "            to each instance of data.\n",
    "        \"\"\"\n",
    "        x, y = sample\n",
    "        x /= self.total_instances\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating instance of transform and using tranform parameter from out dataset's constructor, we can initialise transformation in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transform_my_data(0.2)\n",
    "normalise = normalise_my_data(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = toyDataset(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_dataset = toyDataset(transform=normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loop to print out first 10 elements in dataset\n",
    "\n",
    "for i in range(5):\n",
    "    print(data[i])\n",
    "    print(transformed_dataset[i])\n",
    "    print(normalised_dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing multiple transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transform, normalise])\n",
    "data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Compose object wil perform each transorm concurrently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = toyDataset(transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with real dataset\n",
    "\n",
    "So far,\n",
    "1. dataset was not real and was small, therefore we initialised at __init__(), which must not be done for real datasets, as it will load the entire dataset at once, consuming large memory.\n",
    "2. we have iterated through the dataset using for loop, where we miss various features like, batching, shuffling, load the data in multiprocessing environment. Hence we will use dataloader (iterator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./../data/fMNIST/\"\n",
    "csv_file = \"index.csv\"\n",
    "csv_path = os.path.join(directory+csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = pd.read_csv(csv_path)\n",
    "data_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filename, Label/class\n",
    "data_name.iloc[0,1], data_name.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = data_name.iloc[0,1]\n",
    "image_path = os.path.join(directory+image_name)\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(data_name.iloc[0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fashionDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        csv_path = os.path.join(root_dir+csv_file)\n",
    "        self.csv_file = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            to fetch instances of dataset\n",
    "            idx :: index\n",
    "        \"\"\"\n",
    "        #Loading the image\n",
    "        img_name = os.path.join(self.root_dir+self.csv_file.iloc[idx, 1])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        #Loading the label\n",
    "        label = self.csv_file.iloc[idx, 0]\n",
    "        \n",
    "        #Applying transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating object of dataset\n",
    "fdata = fashionDataset(csv_file, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching length of total instances\n",
    "len(fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing a particulare instance of a dataset\n",
    "img = fdata[100]\n",
    "\n",
    "plt.imshow(img[0],cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(img[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of transform, torchvision provides several built-in transformation for images, like, CenterCrop, ColorJitter, Pad, ToTensor, etc. Click [here](https://pytorch.org/docs/stable/torchvision/transforms.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transformation = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])\n",
    "newFData = fashionDataset(csv_file=csv_file, root_dir=directory, transform=img_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the image for display\n",
    "def show(sample, shape=(28,28)):\n",
    "    plt.imshow(sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title(sample[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing a particulare instance of a dataset\n",
    "img = newFData[100]\n",
    "show(img, shape=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    show(newFData[i], shape=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating over dataset using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(newFData, batch_size=5, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    for i in range(sample_batched[0].shape[0]):\n",
    "        sample = (sample_batched[0][i], sample_batched[1][i])\n",
    "        show(sample, shape=(20,20))\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with torchvision/torch pre-build datasets\n",
    "\n",
    "Click [here](https://pytorch.org/docs/stable/torchvision/datasets.html) to explore different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the pre-built mnist dataset\n",
    "mnist_dataset = dsets.MNIST(root='./../data/',\n",
    "                           train=False, # If True, creates dataset from training.pt, otherwise from test.pt.\n",
    "                           download=True,\n",
    "                           transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the dataset object contains a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(mnist_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the previously referred boston housing dataset from sklearn\n",
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data():\n",
    "    inp_data = boston.data\n",
    "    age = inp_data[:, 6]\n",
    "    targets = boston.target\n",
    "    \n",
    "    X = Variable(torch.from_numpy(age).type(torch.FloatTensor), requires_grad=False).view(506,1)\n",
    "    y = Variable(torch.from_numpy(targets).type(torch.FloatTensor), requires_grad=False)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Weights and bias for Linear Regression\n",
    "W = Variable(torch.randn(1), requires_grad=True)\n",
    "b = Variable(torch.randn(1), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_input_data()\n",
    "for i in range(10):\n",
    "    y_pred = torch.matmul(X, W) + b\n",
    "    \n",
    "    loss = (y - y_pred).pow(2).mean()\n",
    "    for param in [W, b]:\n",
    "        if param.grad is not None:\n",
    "            param.grad.data.zero_()\n",
    "    loss.backward()\n",
    "    loss = loss.data.item()\n",
    "    losses.append(loss)\n",
    "    if i%2 == 0:\n",
    "        print(loss)\n",
    "    \n",
    "    W.data -= lr * W.grad.data\n",
    "    b.data -= lr * b.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot = np.arange(10)\n",
    "yplot = np.array(losses)\n",
    "plt.plot(xplot,yplot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
