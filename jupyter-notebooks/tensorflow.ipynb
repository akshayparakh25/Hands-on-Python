{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow \n",
    "Open source library for numerical computation using data flow graph. Created and Maintained by Google.<br><br>\n",
    "Tensorflow got it's name from **tensor**, array of arbitrary dmensions. Using Tensorflow, one can manipulate tensors with higher dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Tensorflow?\n",
    "1. Efficient\n",
    "2. Scalable\n",
    "3. Maintainable\n",
    "4. Portable\n",
    "5. Flexible\n",
    "6. Visualization in TensorBoard\n",
    "7. Easy to save and restore models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Tensorflow works?\n",
    "Tensorflow operations creates, destroys, and manipulates tensors. All the computation can be operations can be easily visualized using *computation graph* or *data flow graph*.<br>\n",
    "Graph's **nodes** are operations and **edges** are tensors. Tensors flows through graph, and gets manipulated at each node by an operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "A tensor is an n-d array,\n",
    "* 0-d tensor : scalar\n",
    "* 1-d tensor : vector\n",
    "* 2-d tensor : matrix\n",
    "<br>\n",
    "\n",
    "A tensor can be defined as a constant or a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.constant(24)  #scalar\n",
    "v = tf.constant([1, 2, 3, 4], dtype=tf.int64, name='vector')  #vector\n",
    "m = tf.constant([[1,2], [3,4]]) #matrix\n",
    "t = tf.constant( [ [[1,2,3],[2,3,4],[3,4,5]] , [[4,5,6],[5,6,7],[6,7,8]] , [[7,8,9],[8,9,10],[9,10,11]] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant(24, name=\"scalar\") creates a new tf.Operation named \"scalar\" and returns a tf.Tensor named \"scalar:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it just show the name, shape and type of the tensor in the graph. We will see it's value when we run it in a TensorFlow session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.Session() to evaluate the graph\n",
    "A Session object encapsulates the environment in which memory is allocated for storing values of variables, operations are executed, and tensors are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(s)\n",
    "    print (\"Scalar (1 entry):\\n %s \\n\" % result)\n",
    "    result = sess.run(v)\n",
    "    print (\"Vector (3 entries) :\\n %s \\n\" % result)\n",
    "    result = sess.run(m)\n",
    "    print (\"Matrix (3x3 entries):\\n %s \\n\" % result)\n",
    "    result = sess.run(t)\n",
    "    print (\"Tensor (3x3x3 entries) :\\n %s \\n\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape, v.shape, m.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a graph\n",
    "g = tf.Graph()\n",
    "\n",
    "#Setting the generated graph as default graph\n",
    "with g.as_default():\n",
    "    x = tf.constant(5, name=\"x\")\n",
    "    y = tf.constant(4, name=\"y\")\n",
    "    \n",
    "    add = tf.add(x, y, name=\"add\")\n",
    "    mul = tf.multiply(x, y, name=\"mul\")\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(add))\n",
    "        print(mul.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.constant(5, name=\"x\")\n",
    "    y = tf.constant(4, name=\"y\")\n",
    "    \n",
    "    add = tf.add(x, y, name=\"add\")\n",
    "    mul = tf.multiply(x, y, name=\"mul\")\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #sess.run(fetches) will help you fetch multiple values, eval() cannot.\n",
    "        a, m = sess.run(fetches=[add, mul])\n",
    "        print(a)\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph3 = tf.Graph()\n",
    "with graph3.as_default():\n",
    "    Matrix_one = tf.constant([[1,2,3],[2,3,4],[3,4,5]])\n",
    "    Matrix_two = tf.constant([[2,2,2],[2,2,2],[2,2,2]])\n",
    "\n",
    "    add_1_operation = tf.add(Matrix_one, Matrix_two)\n",
    "    add_2_operation = Matrix_one + Matrix_two\n",
    "\n",
    "with tf.Session(graph =graph3) as sess:\n",
    "    result = sess.run(add_1_operation)\n",
    "    print (\"Defined using tensorflow function :\")\n",
    "    print(result)\n",
    "    result = sess.run(add_2_operation)\n",
    "    print (\"Defined using normal expressions :\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph4 = tf.Graph()\n",
    "with graph4.as_default():\n",
    "    Matrix_one = tf.constant([[2,3],[3,4]])\n",
    "    Matrix_two = tf.constant([[2,3],[3,4]])\n",
    "\n",
    "    mul_operation = tf.matmul(Matrix_one, Matrix_two)\n",
    "\n",
    "with tf.Session(graph = graph4) as sess:\n",
    "    result = sess.run(mul_operation)\n",
    "    print (\"Defined using tensorflow function :\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow variables are used to share and persistent some stats that are manipulated by our program. That is, when you define a variable, TensorFlow adds a tf.Operation to your graph. Then, this operation will store a writable tensor value that persists between tf.Session.run calls. So, you can update the value of a variable through each run, while you cannot update tensor (e.g a tensor created by tf.constant()) through multiple runs in a session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variable using Variable object\n",
    "v_s = tf.Variable(5)\n",
    "v_v = tf.Variable([1, 2, 3, 4], dtype=tf.int32)\n",
    "v_m = tf.Variable(tf.zeros([25,4]), dtype=tf.float32, name=\"matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define variables we use the command tf.Variable(). To be able to use variables in a computation graph it is necessary to initialize them before running the graph in a session. This is done by running tf.global_variables_initializer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = tf.assign(v_s, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we use the tf.assign(reference_variable, value_to_update) command. tf.assign takes in two arguments, the reference_variable to update, and assign it to the value_to_update it by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated earlier, Variables must be initialized by running an initialization operation after having launched the graph. We first have to add the initialization operation to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init_op)\n",
    "    print(session.run(v_s))\n",
    "    session.run(update)\n",
    "    print(session.run(v_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variable with tf.get_variable method\n",
    "Weights = tf.get_variable(\"Weights\", shape=(25,4), initializer=tf.random_uniform_initializer())\n",
    "Bias = tf.get_variable(\"Bias\", initializer=tf.random.normal([25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    weights = tf.get_variable(\"Weights\", shape=(25,4), initializer=tf.random_uniform_initializer())\n",
    "    bias = tf.get_variable(\"Bias\", initializer=tf.random.normal([25]))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #initialising all variables at once\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(weights.eval())\n",
    "        print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Graphs using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists('./graphs'):\n",
    "    shutil.rmtree('./graphs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(5, name=\"x\")\n",
    "y = tf.constant(4, name=\"y\")\n",
    "\n",
    "add = tf.add(x, y, name=\"add\")\n",
    "mul = tf.multiply(x, y, name=\"mul\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Creates the summary writer\n",
    "    #After graph definition\n",
    "    #Before Session\n",
    "    #Since we not created a graph explicitly,\n",
    "    #Every operation is being done on default_graph\n",
    "    writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "    a, m = sess.run(fetches=[add, mul])\n",
    "    print(a, m)\n",
    "    \n",
    "#To access graph in Tensorboard\n",
    "#0. Copy the code. Add import tensorflow as tf (at the top). Save the file as tboard.py.\n",
    "#1. Open terminal. Run python(or python3) tboard.py.\n",
    "#2. Check for graphs folder in the same directory. \n",
    "#3. If it is present. Run: tensorboard --logdir=\"./graphs\" --port 6006\n",
    "#4. Open browser and go to: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are using Jypyter Notebook, You can try the following command (uncomment next line)\n",
    "# !tensorboard --logdir=\"./graphs\" --port 6008\n",
    "#Open browser and go to: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "A placeholder is simply a variable that we will assign data to at a later date. It allows us to create our operations and build our computation graph, without needing the data.\n",
    "<br>\n",
    "Placeholders are simplest way to load data, but it is not efficient for loading large data. You can go for estimators or other options that follows in eager execution mode or tensorflow==2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a placeholder\n",
    "data = tf.placeholder(shape=[25,4], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "b = tf.constant([5, 5, 5], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value to the placeholder is provided during the run\n",
    "#Using feed_dict\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(add, feed_dict={a:[4,4,4]})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example to show how Placeholders and Variables are created in data flow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists('./graphs_linear/'):\n",
    "    shutil.rmtree('./graphs_linear/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inp_data = np.linspace(0, 100, 100, dtype=np.float32).reshape(25,4)\n",
    "\n",
    "glinear = tf.Graph()\n",
    "with glinear.as_default():\n",
    "    \n",
    "    inputs = tf.placeholder(shape=[25,4], dtype=tf.float32)\n",
    "\n",
    "    W = tf.get_variable(\"W\", shape=(1, 4), initializer=tf.random_uniform_initializer())\n",
    "    B = tf.get_variable(\"B\", initializer=tf.random.normal([25,1]))\n",
    "\n",
    "    y = tf.matmul(inputs, tf.transpose(W)) + B\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter('./graphs_linear', tf.get_default_graph())\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        res = sess.run(y, feed_dict={inputs:inp_data})\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ucomment the line below to visualize in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=\"./graphs_linear/\" --port 6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Defining a linear regression in simple terms, is the approximation of a linear model used to describe the relationship between two or more variables. In a simple linear regression there are two variables, the dependent variable, which can be seen as the \"state\" or \"final goal\" that we study and try to predict, and the independent variables, also known as explanatory variables, which can be seen as the \"causes\" of the \"states\". \n",
    "\n",
    "When more than one independent variable is present the process is called multiple linear regression. <br>\n",
    "When multiple dependent variables are predicted the process is known as multivariate linear regression.\n",
    "\n",
    "The equation of a simple linear model is\n",
    "\n",
    "$$Y = a X + b $$\n",
    "\n",
    "Where Y is the dependent variable and X is the independent variable, and <b>a</b> and <b>b</b> being the parameters we adjust. <b>a</b> is known as \"slope\" or \"gradient\" and <b>b</b> is the \"intercept\". You can interpret this equation as Y being a function of X, or Y being dependent on X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../data/imdbtop1000/imdb_data.csv', sep='\\t')\n",
    "df = df.rename(columns={'User Votes': 'Votes',\n",
    "                        'Imdb Rating': 'Rating',\n",
    "                       'Gross(in Million Dollars)': 'Earnings',\n",
    "                       'Runtime(Minutes)' : 'Runtime'})\n",
    "#It is very important to normalise the input features in a proper range\n",
    "#It helps in avoiding very large calculations\n",
    "df.Votes = df.Votes / 1000000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between columns to identify best feature for training a model\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(df.Votes)\n",
    "train_y = np.asarray(df.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Analysis of data points Votes Vs Rating\")\n",
    "sns.scatterplot(x=train_x, y=train_y)\n",
    "plt.xlabel('User Votes')\n",
    "plt.ylabel('IMDB Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising weights and bias. And defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(10.0)\n",
    "b = tf.Variable(12.3)\n",
    "y = w * train_x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to define a loss function for our regression, so we can train our model to better fit our data. In a linear regression, we minimize the squared error of the difference between the predicted values(obtained from the equation) and the target values (the data that we have). In other words we want to minimize the square of the predicted values minus the target value. So we define the equation to be minimized as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the optimizer method. The gradient Descent optimizer takes in parameter: learning rate, which corresponds to the speed with which the optimizer should learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training method of our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all previous steps under a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_lin_reg = tf.Graph()\n",
    "with graph_lin_reg.as_default():\n",
    "    #Placeholder for input features\n",
    "    X = tf.placeholder(shape=input_shape, dtype=tf.float32)\n",
    "    \n",
    "    #Initialising weights\n",
    "    w = tf.Variable(10.0)\n",
    "    b = tf.Variable(12.3)\n",
    "    \n",
    "    #defining model\n",
    "    y = w * X + b\n",
    "    \n",
    "    #defining loss\n",
    "    loss = tf.reduce_mean(tf.square(y - train_y))\n",
    "    \n",
    "    #defining optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "    \n",
    "    #initialising training\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter('./graphs_linearRegression', tf.get_default_graph())\n",
    "    sess.run(init)\n",
    "    \n",
    "    loss_values = []\n",
    "    train_data = []\n",
    "    for step in range(100):\n",
    "        _, loss_val, w_val, b_val = sess.run([train, loss, w, b], feed_dict={X:train_x})\n",
    "        loss_values.append(loss_val)\n",
    "        if step % 5 == 0:\n",
    "            print(step, loss_val, w_val, b_val)\n",
    "            train_data.append([w_val, b_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ucomment the line below to visualize in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=\"./graphs_linearRegression/\" --port 6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(loss_values, label='loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
