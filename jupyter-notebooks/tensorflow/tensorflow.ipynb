{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow \n",
    "Open source library for numerical computation using data flow graph. Created and Maintained by Google.<br><br>\n",
    "Tensorflow got it's name from **tensor**, array of arbitrary dmensions. Using Tensorflow, one can manipulate tensors with higher dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Tensorflow?\n",
    "1. Efficient\n",
    "2. Scalable\n",
    "3. Maintainable\n",
    "4. Portable\n",
    "5. Flexible\n",
    "6. Visualization in TensorBoard\n",
    "7. Easy to save and restore models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Tensorflow works?\n",
    "Tensorflow operations creates, destroys, and manipulates tensors. All the computation can be operations can be easily visualized using *computation graph* or *data flow graph*.<br>\n",
    "Graph's **nodes** are operations and **edges** are tensors. Tensors flows through graph, and gets manipulated at each node by an operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor\n",
    "A tensor is an n-d array,\n",
    "* 0-d tensor : scalar\n",
    "* 1-d tensor : vector\n",
    "* 2-d tensor : matrix\n",
    "<br>\n",
    "\n",
    "A tensor can be defined as a constant or a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.constant(24)  #scalar\n",
    "v = tf.constant([1, 2, 3, 4], dtype=tf.int64, name='vector')  #vector\n",
    "m = tf.constant([[1,2], [3,4]]) #matrix\n",
    "t = tf.constant( [ [[1,2,3],[2,3,4],[3,4,5]] , [[4,5,6],[5,6,7],[6,7,8]] , [[7,8,9],[8,9,10],[9,10,11]] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.constant(24, name=\"scalar\") creates a new tf.Operation named \"scalar\" and returns a tf.Tensor named \"scalar:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it just show the name, shape and type of the tensor in the graph. We will see it's value when we run it in a TensorFlow session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using tf.Session() to evaluate the graph\n",
    "A Session object encapsulates the environment in which memory is allocated for storing values of variables, operations are executed, and tensors are evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar (1 entry):\n",
      " 24 \n",
      "\n",
      "Vector (3 entries) :\n",
      " [1 2 3 4] \n",
      "\n",
      "Matrix (3x3 entries):\n",
      " [[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Tensor (3x3x3 entries) :\n",
      " [[[ 1  2  3]\n",
      "  [ 2  3  4]\n",
      "  [ 3  4  5]]\n",
      "\n",
      " [[ 4  5  6]\n",
      "  [ 5  6  7]\n",
      "  [ 6  7  8]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [ 8  9 10]\n",
      "  [ 9 10 11]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(s)\n",
    "    print (\"Scalar (1 entry):\\n %s \\n\" % result)\n",
    "    result = sess.run(v)\n",
    "    print (\"Vector (3 entries) :\\n %s \\n\" % result)\n",
    "    result = sess.run(m)\n",
    "    print (\"Matrix (3x3 entries):\\n %s \\n\" % result)\n",
    "    result = sess.run(t)\n",
    "    print (\"Tensor (3x3x3 entries) :\\n %s \\n\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]),\n",
       " TensorShape([Dimension(4)]),\n",
       " TensorShape([Dimension(2), Dimension(2)]),\n",
       " TensorShape([Dimension(3), Dimension(3), Dimension(3)]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape, v.shape, m.shape, t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#Creating a graph\n",
    "g = tf.Graph()\n",
    "\n",
    "#Setting the generated graph as default graph\n",
    "with g.as_default():\n",
    "    x = tf.constant(5, name=\"x\")\n",
    "    y = tf.constant(4, name=\"y\")\n",
    "    \n",
    "    add = tf.add(x, y, name=\"add\")\n",
    "    mul = tf.multiply(x, y, name=\"mul\")\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(add))\n",
    "        print(mul.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.constant(5, name=\"x\")\n",
    "    y = tf.constant(4, name=\"y\")\n",
    "    \n",
    "    add = tf.add(x, y, name=\"add\")\n",
    "    mul = tf.multiply(x, y, name=\"mul\")\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #sess.run(fetches) will help you fetch multiple values, eval() cannot.\n",
    "        a, m = sess.run(fetches=[add, mul])\n",
    "        print(a)\n",
    "        print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined using tensorflow function :\n",
      "[[3 4 5]\n",
      " [4 5 6]\n",
      " [5 6 7]]\n",
      "Defined using normal expressions :\n",
      "[[3 4 5]\n",
      " [4 5 6]\n",
      " [5 6 7]]\n"
     ]
    }
   ],
   "source": [
    "graph3 = tf.Graph()\n",
    "with graph3.as_default():\n",
    "    Matrix_one = tf.constant([[1,2,3],[2,3,4],[3,4,5]])\n",
    "    Matrix_two = tf.constant([[2,2,2],[2,2,2],[2,2,2]])\n",
    "\n",
    "    add_1_operation = tf.add(Matrix_one, Matrix_two)\n",
    "    add_2_operation = Matrix_one + Matrix_two\n",
    "\n",
    "with tf.Session(graph =graph3) as sess:\n",
    "    result = sess.run(add_1_operation)\n",
    "    print (\"Defined using tensorflow function :\")\n",
    "    print(result)\n",
    "    result = sess.run(add_2_operation)\n",
    "    print (\"Defined using normal expressions :\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined using tensorflow function :\n",
      "[[13 18]\n",
      " [18 25]]\n"
     ]
    }
   ],
   "source": [
    "graph4 = tf.Graph()\n",
    "with graph4.as_default():\n",
    "    Matrix_one = tf.constant([[2,3],[3,4]])\n",
    "    Matrix_two = tf.constant([[2,3],[3,4]])\n",
    "\n",
    "    mul_operation = tf.matmul(Matrix_one, Matrix_two)\n",
    "\n",
    "with tf.Session(graph = graph4) as sess:\n",
    "    result = sess.run(mul_operation)\n",
    "    print (\"Defined using tensorflow function :\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow variables are used to share and persist some stats that are manipulated by our program. That is, when you define a variable, TensorFlow adds a tf.Operation to your graph. Then, this operation will store a writable tensor value that persists between tf.Session.run calls. So, you can update the value of a variable through each run, while you cannot update tensor (e.g a tensor created by tf.constant()) through multiple runs in a session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating variable using Variable object\n",
    "v_s = tf.Variable(5)\n",
    "v_v = tf.Variable([1, 2, 3, 4], dtype=tf.int32)\n",
    "v_m = tf.Variable(tf.zeros([25,4]), dtype=tf.float32, name=\"matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define variables we use the command tf.Variable(). To be able to use variables in a computation graph it is necessary to initialize them before running the graph in a session. This is done by running tf.global_variables_initializer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = tf.assign(v_s, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we use the tf.assign(reference_variable, value_to_update) command. tf.assign takes in two arguments, the reference_variable to update, and assign it to the value_to_update it by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated earlier, Variables must be initialized by running an initialization operation after having launched the graph. We first have to add the initialization operation to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    session.run(init_op)\n",
    "    print(session.run(v_s))\n",
    "    session.run(update)\n",
    "    print(session.run(v_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable Weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-15-4e5fe2949989>\", line 2, in <module>\n    Weights = tf.get_variable(\"Weights\", shape=(25,4), initializer=tf.random_uniform_initializer())\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4e5fe2949989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Creating variable with tf.get_variable method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mBias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1494\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1237\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    560\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    512\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     synchronization, aggregation, trainable = (\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    862\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 864\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    865\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable Weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-15-4e5fe2949989>\", line 2, in <module>\n    Weights = tf.get_variable(\"Weights\", shape=(25,4), initializer=tf.random_uniform_initializer())\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/akshay/venv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n"
     ]
    }
   ],
   "source": [
    "#Creating variable with tf.get_variable method\n",
    "Weights = tf.get_variable(\"Weights\", shape=(25,4), initializer=tf.random_uniform_initializer())\n",
    "Bias = tf.get_variable(\"Bias\", initializer=tf.random.normal([25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.99679613e-01 5.72880149e-01 7.97352433e-01 4.76609468e-02]\n",
      " [1.45309567e-01 2.71592140e-02 7.42301941e-02 8.92637730e-01]\n",
      " [1.34758353e-01 2.31332541e-01 7.14537382e-01 2.79857516e-01]\n",
      " [7.24956632e-01 7.66727805e-01 8.31718445e-02 2.09059954e-01]\n",
      " [4.53525782e-02 2.70085216e-01 3.33217621e-01 8.06650996e-01]\n",
      " [4.68064547e-01 7.51365542e-01 4.29036856e-01 1.87196255e-01]\n",
      " [4.66478586e-01 4.64671135e-01 8.54185820e-02 5.02733350e-01]\n",
      " [1.13506794e-01 5.74873209e-01 1.01101160e-01 2.47488618e-01]\n",
      " [6.57383442e-01 6.27930045e-01 2.67067671e-01 8.87267113e-01]\n",
      " [7.32314587e-02 6.64256692e-01 7.02024460e-01 8.70902538e-01]\n",
      " [2.92692184e-01 9.94082689e-01 1.19687080e-01 1.02327228e-01]\n",
      " [7.93508172e-01 1.89821482e-01 1.98092818e-01 3.21712136e-01]\n",
      " [2.22542286e-02 3.03220987e-01 9.84072685e-04 3.58362436e-01]\n",
      " [7.48715043e-01 8.98232102e-01 9.74064112e-01 7.15899467e-02]\n",
      " [2.48135328e-02 3.58215094e-01 9.67699409e-01 9.16957140e-01]\n",
      " [3.49476218e-01 4.48064208e-01 5.31490088e-01 4.41013813e-01]\n",
      " [9.39442396e-01 4.50593591e-01 4.36348915e-02 4.87573504e-01]\n",
      " [7.29638100e-01 5.48861384e-01 5.72617054e-01 5.92236757e-01]\n",
      " [3.83742929e-01 9.69095707e-01 9.26986456e-01 6.77115321e-01]\n",
      " [9.43761349e-01 5.46957493e-01 6.37696505e-01 8.22885394e-01]\n",
      " [6.89065456e-03 4.01492476e-01 1.82140708e-01 6.83935523e-01]\n",
      " [2.03077555e-01 4.76231098e-01 9.52685833e-01 5.96934795e-01]\n",
      " [5.40554881e-01 6.65412903e-01 5.21980882e-01 6.49433374e-01]\n",
      " [3.11564445e-01 6.26249313e-02 5.87534070e-01 1.15560532e-01]\n",
      " [6.80766225e-01 5.36794186e-01 3.04371238e-01 2.69660711e-01]]\n",
      "[ 1.3751185e-01 -5.9820056e-02 -6.3573755e-02 -9.0495592e-01\n",
      "  6.6705513e-01  3.0742097e+00 -1.2886421e-03 -3.8180250e-01\n",
      " -1.1728849e+00  1.5727153e+00  1.3512172e-01 -6.8551046e-01\n",
      "  5.0851381e-01 -6.2914729e-01 -3.1604881e+00  5.4708511e-01\n",
      " -3.3042035e-01  2.0409627e+00 -8.1914020e-01  1.3543212e-01\n",
      "  1.2341117e+00 -1.4580773e-01 -2.2620495e-01 -1.5021741e+00\n",
      " -5.1509213e-01]\n"
     ]
    }
   ],
   "source": [
    "g = tf.Graph()\n",
    "\n",
    "with g.as_default():\n",
    "    weights = tf.get_variable(\"Weights\", shape=(25,4), initializer=tf.random_uniform_initializer())\n",
    "    bias = tf.get_variable(\"Bias\", initializer=tf.random.normal([25]))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        #initialising all variables at once\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print(weights.eval())\n",
    "        print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Graphs using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists('./graphs'):\n",
    "    shutil.rmtree('./graphs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 20\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(5, name=\"x\")\n",
    "y = tf.constant(4, name=\"y\")\n",
    "\n",
    "add = tf.add(x, y, name=\"add\")\n",
    "mul = tf.multiply(x, y, name=\"mul\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Creates the summary writer\n",
    "    #After graph definition\n",
    "    #Before Session\n",
    "    #Since we not created a graph explicitly,\n",
    "    #Every operation is being done on default_graph\n",
    "    writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "    a, m = sess.run(fetches=[add, mul])\n",
    "    print(a, m)\n",
    "    \n",
    "#To access graph in Tensorboard\n",
    "#0. Copy the code. Add import tensorflow as tf (at the top). Save the file as tboard.py.\n",
    "#1. Open terminal. Run python(or python3) tboard.py.\n",
    "#2. Check for graphs folder in the same directory. \n",
    "#3. If it is present. Run: tensorboard --logdir=\"./graphs\" --port 6006\n",
    "#4. Open browser and go to: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "TensorBoard 1.14.0 at http://Ubuntu:6008/ (Press CTRL+C to quit)\n",
      "I1003 10:20:15.390483 140286350763776 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:15] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:16.239715 140286350763776 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:16] \"\u001b[37mGET /font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:16.726754 140286350763776 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:16] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:16.728760 140285600691968 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:16] \"\u001b[37mGET /data/environment HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:16.730578 140286359156480 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:16] \"\u001b[37mGET /data/runs HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:16.732365 140285617477376 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:16] \"\u001b[37mGET /data/experiments HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:16.741223 140285600691968 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:16] \"\u001b[37mGET /font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:17.071437 140286359156480 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:17] \"\u001b[37mGET /data/plugin/graphs/info HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:17.073570 140285600691968 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:17] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:17.293204 140285600691968 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:17] \"\u001b[37mGET /data/plugin/graphs/graph?run=.&conceptual=false HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:20:17.653187 140285600691968 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:20:17] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#If you are using Jypyter Notebook, You can try the following command (uncomment next line)\n",
    "!tensorboard --logdir=\"./graphs\" --port 6008\n",
    "#Open browser and go to: http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders\n",
    "A placeholder is simply a variable that we will assign data to at a later time. It allows us to create our operations and build our computation graph, without needing the data.\n",
    "<br>\n",
    "Placeholders are simplest way to load data, but it is not efficient for loading large data. You can go for estimators or other options that follows in eager execution mode or tensorflow==2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a placeholder\n",
    "data = tf.placeholder(shape=[25,4], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32, shape=[3])\n",
    "b = tf.constant([5, 5, 5], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "#Value to the placeholder is provided during the run\n",
    "#Using feed_dict\n",
    "with tf.Session() as sess:\n",
    "    res = sess.run(add, feed_dict={a:[4,4,4]})\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example to show how Placeholders and Variables are created in data flow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists('./graphs_linear/'):\n",
    "    shutil.rmtree('./graphs_linear/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "[[ 0.4380539 ]\n",
      " [-0.330014  ]\n",
      " [ 1.0499535 ]\n",
      " [ 0.4561507 ]\n",
      " [ 1.5493466 ]\n",
      " [ 0.02349877]\n",
      " [ 1.4971657 ]\n",
      " [ 3.0115342 ]\n",
      " [ 1.9058092 ]\n",
      " [ 0.05143076]\n",
      " [ 0.43108734]\n",
      " [ 0.05005777]\n",
      " [-0.79303914]\n",
      " [ 0.65684104]\n",
      " [ 1.1828899 ]\n",
      " [-0.19562519]\n",
      " [ 0.81509984]\n",
      " [ 1.8582444 ]\n",
      " [ 0.87833464]\n",
      " [ 1.3966749 ]\n",
      " [ 0.9746148 ]\n",
      " [-0.7965375 ]\n",
      " [ 0.25242484]\n",
      " [ 1.6816807 ]\n",
      " [ 1.7769268 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inp_data = np.random.rand(100,1).reshape(25,4)\n",
    "\n",
    "glinear = tf.Graph()\n",
    "with glinear.as_default():\n",
    "    \n",
    "    inputs = tf.placeholder(shape=[25,4], dtype=tf.float32)\n",
    "\n",
    "    W = tf.get_variable(\"W\", shape=(1, 4), initializer=tf.random_uniform_initializer())\n",
    "    B = tf.get_variable(\"B\", initializer=tf.random.normal([25,1]))\n",
    "\n",
    "    y = tf.matmul(inputs, tf.transpose(W)) + B\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        writer = tf.summary.FileWriter('./graphs_linear', tf.get_default_graph())\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        res = sess.run(y, feed_dict={inputs:inp_data})\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ucomment the line below to visualize in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/akshay/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "TensorBoard 1.14.0 at http://Ubuntu:6008/ (Press CTRL+C to quit)\n",
      "I1003 10:23:28.091343 140334998562560 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:28] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:28.511120 140334998562560 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:28] \"\u001b[37mGET /font-roboto/oMMgfZMQthOryQo9n22dcuvvDin1pK8aKteLpeZ5c0A.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.208978 140334256883456 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/environment HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.211205 140334998562560 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.212108 140334248490752 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/runs HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.213207 140334265276160 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/experiments HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.226132 140334256883456 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /font-roboto/RxZJdnzeo3R5zSexge8UUZBw1xU1rKptJj_0jans920.woff2 HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.492817 140334256883456 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.493948 140334248490752 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/plugin/graphs/info HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.682444 140334256883456 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/plugin/graphs/graph?run=.&conceptual=false HTTP/1.1\u001b[0m\" 200 -\n",
      "I1003 10:23:29.999372 140334256883456 _internal.py:122] ::ffff:127.0.0.1 - - [03/Oct/2020 10:23:29] \"\u001b[37mGET /data/plugins_listing HTTP/1.1\u001b[0m\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"./graphs_linear/\" --port 6008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Defining a linear regression in simple terms, is the approximation of a linear model used to describe the relationship between two or more variables. In a simple linear regression there are two variables, the dependent variable, which can be seen as the \"state\" or \"final goal\" that we study and try to predict, and the independent variables, also known as explanatory variables, which can be seen as the \"causes\" of the \"states\". \n",
    "\n",
    "When more than one independent variable is present the process is called multiple linear regression. <br>\n",
    "When multiple dependent variables are predicted the process is known as multivariate linear regression.\n",
    "\n",
    "The equation of a simple linear model is\n",
    "\n",
    "$$Y = a X + b $$\n",
    "\n",
    "Where Y is the dependent variable and X is the independent variable, and <b>a</b> and <b>b</b> being the parameters we adjust. <b>a</b> is known as \"slope\" or \"gradient\" and <b>b</b> is the \"intercept\". You can interpret this equation as Y being a function of X, or Y being dependent on X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and pre-processing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./../data/imdbtop1000/imdb_data.csv' does not exist: b'./../data/imdbtop1000/imdb_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ab47e2be82a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./../data/imdbtop1000/imdb_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m df = df.rename(columns={'User Votes': 'Votes',\n\u001b[1;32m      3\u001b[0m                         \u001b[0;34m'Imdb Rating'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Rating'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                        \u001b[0;34m'Gross(in Million Dollars)'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Earnings'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                        'Runtime(Minutes)' : 'Runtime'})\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./../data/imdbtop1000/imdb_data.csv' does not exist: b'./../data/imdbtop1000/imdb_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./../data/imdbtop1000/imdb_data.csv', sep='\\t')\n",
    "df = df.rename(columns={'User Votes': 'Votes',\n",
    "                        'Imdb Rating': 'Rating',\n",
    "                       'Gross(in Million Dollars)': 'Earnings',\n",
    "                       'Runtime(Minutes)' : 'Runtime'})\n",
    "#It is very important to normalise the input features in a proper range\n",
    "#It helps in avoiding very large calculations\n",
    "df.Votes = df.Votes / 1000000\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation between columns to identify best feature for training a model\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(df.Votes)\n",
    "train_y = np.asarray(df.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Analysis of data points Votes Vs Rating\")\n",
    "sns.scatterplot(x=train_x, y=train_y)\n",
    "plt.xlabel('User Votes')\n",
    "plt.ylabel('IMDB Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising weights and bias. And defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(10.0)\n",
    "b = tf.Variable(12.3)\n",
    "y = w * train_x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to define a loss function for our regression, so we can train our model to better fit our data. In a linear regression, we minimize the squared error of the difference between the predicted values(obtained from the equation) and the target values (the data that we have). In other words we want to minimize the square of the predicted values minus the target value. So we define the equation to be minimized as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the optimizer method. The gradient Descent optimizer takes in parameter: learning rate, which corresponds to the speed with which the optimizer should learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training method of our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all previous steps under a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_lin_reg = tf.Graph()\n",
    "with graph_lin_reg.as_default():\n",
    "    #Placeholder for input features\n",
    "    X = tf.placeholder(shape=input_shape, dtype=tf.float32)\n",
    "    \n",
    "    #Initialising weights\n",
    "    w = tf.Variable(10.0)\n",
    "    b = tf.Variable(12.3)\n",
    "    \n",
    "    #defining model\n",
    "    y = w * X + b\n",
    "    \n",
    "    #defining loss\n",
    "    loss = tf.reduce_mean(tf.square(y - train_y))\n",
    "    \n",
    "    #defining optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "    \n",
    "    #initialising training\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    writer = tf.summary.FileWriter('./graphs_linearRegression', tf.get_default_graph())\n",
    "    sess.run(init)\n",
    "    \n",
    "    loss_values = []\n",
    "    train_data = []\n",
    "    for step in range(100):\n",
    "        _, loss_val, w_val, b_val = sess.run([train, loss, w, b], feed_dict={X:train_x})\n",
    "        loss_values.append(loss_val)\n",
    "        if step % 5 == 0:\n",
    "            print(step, loss_val, w_val, b_val)\n",
    "            train_data.append([w_val, b_val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ucomment the line below to visualize in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir=\"./graphs_linearRegression/\" --port 6008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(loss_values, label='loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
