{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader Class\n",
    "\n",
    "PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class and loading dataset\n",
    "\n",
    "`Dataset` stores the samples and their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f52dd6e11f8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "#Forces to give same random number every time it gets compiled\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Custom dataset should inherit Dataset and override,\n",
    "1. \\_\\_init\\_\\_(): The \\_\\_init\\_\\_ function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms\n",
    "2. \\_\\_len\\_\\_(): The \\_\\_len\\_\\_ function returns the number of samples in our dataset.\n",
    "3. \\_\\_getitem\\_\\_(): The \\_\\_getitem\\_\\_ function loads and returns a sample from the dataset at the given index `index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class to load sample dummy dataset\n",
    "class toyDataset(Dataset):\n",
    "    #Constructor with default values\n",
    "    def __init__(self, length=10, transform=None, target_transform=None):\n",
    "        self.len = length\n",
    "        #x :: input features\n",
    "        self.x = 2 * torch.randint(0, 101,(length, 2), dtype=torch.float64)\n",
    "        #y :: target labels\n",
    "        self.y = torch.ones(length, 1)\n",
    "        #Whether data features need to transformed (like, normalization, etc)\n",
    "        self.transform = transform\n",
    "        #Whether data labels need to transformed (like, generating one-hot vectors, etc)\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    #Method overriding to return the total number of instances \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    #Method overriding to return data samples\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample[0] = self.transform(sample[0])\n",
    "        if self.target_transform:\n",
    "            sample[1] = self.transform(sample[1])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([46., 50.], dtype=torch.float64), tensor([1.]))\n",
      "(tensor([ 74., 200.], dtype=torch.float64), tensor([1.]))\n",
      "(tensor([200., 190.], dtype=torch.float64), tensor([1.]))\n",
      "(tensor([144.,  28.], dtype=torch.float64), tensor([1.]))\n",
      "(tensor([ 98., 168.], dtype=torch.float64), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "#Creating instance of toyDataset and accessing example instances\n",
    "data = toyDataset()\n",
    "for i in range(5):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform\n",
    "Most of time, we need to do some type of tranformation in the dataset, like normalising the data, setting the image size, etc. Thus, there is need to write some pre-processing code. <br>\n",
    "It is ideal to implement them as class rather than functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transform_my_data(object):\n",
    "    def __init__(self, tranformation_params):\n",
    "        \"\"\"\n",
    "            Constructor\n",
    "        \"\"\"\n",
    "        self.tranformation_params = tranformation_params\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "            Executor:\n",
    "            Necessary tranformation\n",
    "            to each instance of data.\n",
    "            \n",
    "        \"\"\"\n",
    "        x, y = sample\n",
    "        x *= self.tranformation_params\n",
    "        \n",
    "        return x, y       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalise_my_data(object):\n",
    "    def __init__(self, total_instances):\n",
    "        \"\"\"\n",
    "            Constructor\n",
    "        \"\"\"\n",
    "        self.total_instances = total_instances\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "            Executor:\n",
    "            Necessary tranformation\n",
    "            to each instance of data.\n",
    "        \"\"\"\n",
    "        x, y = sample\n",
    "        x /= self.total_instances\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating instance of transform and using tranform parameter from out dataset's constructor, we can initialise transformation in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transform_my_data(0.2)\n",
    "normalise = normalise_my_data(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_dataset = toyDataset(transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_dataset = toyDataset(transform=normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loop to print out first 10 elements in dataset\n",
    "\n",
    "for i in range(5):\n",
    "    print(data[i])\n",
    "    print(transformed_dataset[i])\n",
    "    print(normalised_dataset[i])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing multiple transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transform, normalise])\n",
    "data_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Compose object wil perform each transorm concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = toyDataset(transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with real dataset\n",
    "\n",
    "So far,\n",
    "1. dataset was not real and was small, therefore we initialised at __init__(), which must not be done for real datasets, as it will load the entire dataset at once, consuming large memory.\n",
    "2. we have iterated through the dataset using for loop, where we miss various features like, batching, shuffling, load the data in multiprocessing environment. Hence we will use dataloader (iterator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./../../data/fmnist-sample/\"\n",
    "csv_file = \"index.csv\"\n",
    "csv_path = os.path.join(directory+csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = pd.read_csv(csv_path)\n",
    "data_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filename, Label/class\n",
    "data_name.iloc[0,1], data_name.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = data_name.iloc[0,1]\n",
    "image_path = os.path.join(directory+image_name)\n",
    "image = Image.open(image_path)\n",
    "plt.imshow(image,cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(data_name.iloc[0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fashionDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        csv_path = os.path.join(root_dir+csv_file)\n",
    "        self.csv_file = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "            to fetch instances of dataset\n",
    "            idx :: index\n",
    "        \"\"\"\n",
    "        #Loading the image\n",
    "        img_name = os.path.join(self.root_dir+self.csv_file.iloc[idx, 1])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        #Loading the label\n",
    "        label = self.csv_file.iloc[idx, 0]\n",
    "        \n",
    "        #Applying transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating object of dataset\n",
    "fdata = fashionDataset(csv_file, directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching length of total instances\n",
    "len(fdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing a particulare instance of a dataset\n",
    "img = fdata[100]\n",
    "\n",
    "plt.imshow(img[0],cmap='gray', vmin=0, vmax=255)\n",
    "plt.title(img[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of transform, torchvision provides several built-in transformation for images, like, CenterCrop, ColorJitter, Pad, ToTensor, etc. Click [here](https://pytorch.org/docs/stable/torchvision/transforms.html) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transformation = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])\n",
    "newFData = fashionDataset(csv_file=csv_file, root_dir=directory, transform=img_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to load the image for display\n",
    "def show(sample, shape=(28,28)):\n",
    "    plt.imshow(sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title(sample[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing a particulare instance of a dataset\n",
    "img = newFData[100]\n",
    "show(img, shape=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    show(newFData[i], shape=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over dataset using DataLoader\n",
    "\n",
    "`DataLoader` wraps an iterable around the `Dataset` to enable easy access to the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(newFData, batch_size=5, shuffle=True, num_workers=5)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    for i in range(sample_batched[0].shape[0]):\n",
    "        sample = (sample_batched[0][i], sample_batched[1][i])\n",
    "        show(sample, shape=(20,20))\n",
    "    if i_batch == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with torchvision/torch pre-build datasets\n",
    "\n",
    "Click [here](https://pytorch.org/docs/stable/torchvision/datasets.html) to explore different datasets.\n",
    "\n",
    "Common parameters across torchvision datasets\n",
    "\n",
    "1. `root:` the path where the data is stored.\n",
    "2. `train:` specifies training or test data.\n",
    "3. `download:` downloads the dataset if not available at root\n",
    "4. `transform:` feature transformation\n",
    "5. `target_transform:` label transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "\n",
    "#importing the pre-built mnist dataset\n",
    "mnist_dataset = dsets.MNIST(root='./../data/',\n",
    "                           train=False, # If True, creates dataset from training.pt, otherwise from test.pt.\n",
    "                           download=True,\n",
    "                           transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the dataset object contains a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(mnist_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with torchtext pre-built dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = IMDB(root='./../data/IMDB', split='train')\n",
    "test_iter = IMDB(root='./../data/IMDB', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for label, line in train_iter:\n",
    "    train_data.append((label, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for label, line in test_iter:\n",
    "    test_data.append((label, line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "label, line = train_data[sample_idx]\n",
    "print(sample_idx, '\\t', line, '\\t', label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
